Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Policy/Curiosity Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Policy/Curiosity Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Losses/Curiosity Forward Loss,Losses/Curiosity Inverse Loss,Is Training
150000,1.3997135,22.631299734748012,-1.1490668,0.5398144,-1.1727084834524926,-1.1727084834524926,0.01534251502883482,1.7294908,0.19548005,0.00029118938,0.19706312,0.0048534498,0.05905296,0.4158478,1.0
160000,1.3967488,21.940366972477065,-0.9625099,0.48826018,-1.1512128169383478,-1.1512128169383478,0.025087368228139544,1.7840204,0.19313328,0.00029063903,0.1968797,0.0048442963,0.05366656,0.41711295,1.0
